2024.04.14 成长日志

本周我完成任务简单，主要就是重新写了一个 `bert_sst2.py`，在写的过程中深入理解 bert 模型应用于文本分类的原理。

1. （4.08-4.12）完成了 `bert_sst2_origin.py` 的编写，编写过程没有什么难点。
  
2. （4.12-4.14）针对 `bert_sst2_origin.py` 中的bug进行修复，但并不顺利。
  
    在 `bert_sst2_origin.py` 中，其他的问题都很快解决，但代码输出的 `accuracy` 始终大于 $1$ ，我尝试寻找问题所在，于是编写了以下 debug 片段：

    ```python
    print(f"\n\n-------------------------DEBUG-INFO {index}-------------------------")
    print(f"len(bert_output): {len(bert_output)}")
    print(f"Acc: {acc/len(bert_output):.2f}")
    print(f"Acc_from_sklearn: {acc_debug:.2f}")
    print(f"Debug_bert_output: {debug_bert_output}")
    print(f"Debug_target: {debug_target}")
    print("-------------------------DEBUG-INFO END-------------------------\n\n")
    index += 1
    ```

    输出如下：
    
    ```
    ------------------DEBUG-INFO 3------------------
    len(test_dataloader): 8
    Acc: 1.20
    Acc_from_sklearn: 0.40
    Debug_bert_output: tensor([[-0.2352, -0.3552],
    [ 0.1977, -0.7350],
    [-0.0712, -0.1965],
    [ 0.2336, -0.6934],
    [-0.0310, -0.2580]], device='cuda:0', grad_fn=<AddmmBackward0>)
    Debug_target: tensor([0, 1, 1, 1, 0], device='cuda:0')
    ------------------DEBUG-INFO END-----------------
    
	Acc: 2.40
	```
	
	
	
	在输出中，我发现`acc`的值好像是不断累加的，这属于正常现象，但在一个`batch`结束后，`acc/len(test_dataloader)`的值大于1。
	
	在原版代码中，这样的写法并没有什么问题，但不知为何，我的电脑上就是得不到正确答案，改了很多地方，还是没能解决。
	
	最后，我向师兄求助。师兄看了我的代码，给出了解释：
	
	> `len(dataloader)`返回的是`batch`的数量，这并不是我们想要的，我们需要的是一个`batch`的总数据量，用正确预测的个数来除以它，即可得到正确的精准度；然而，`batch`的个数是小于总数据量的，所以并不能得到答案。
	
	将代码改为
	
	```python
	print(f"Acc: {acc / len(test_dataloader.dataset:.2f)}")
	```
	
	
	
	即可得到正确范围内的acc值，至于其背后的原理，时间有限，没有深入探究。这会成为我下一周的任务之一。
	
	本周的任务紧赶慢赶地完成了。
	
	---

